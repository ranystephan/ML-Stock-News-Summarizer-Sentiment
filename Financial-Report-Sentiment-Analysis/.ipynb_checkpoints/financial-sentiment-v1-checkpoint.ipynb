{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import getopt\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USERNAME = \"rcs04@mail.aub.edu\"\n",
    "PASSWORD = \"Iloveapplle123!!\"\n",
    "CLIENT_ID = \"d383a5a913ea43739e4cd6fb50d8a26d4cee32da\"\n",
    "\n",
    "\n",
    "def readCredsFromFile(filePathName):\n",
    "    # Read valid credentials from file\n",
    "    global USERNAME, PASSWORD, CLIENT_ID\n",
    "    credFile = open(filePathName, \"r\")    # one per line\n",
    "    # --- RDP MACHINE ID---\n",
    "    # --- LONG PASSWORD---\n",
    "    # --- GENERATED CLIENT ID---\n",
    "\n",
    "    USERNAME = credFile.readline().rstrip('\\n')\n",
    "    PASSWORD = credFile.readline().rstrip('\\n')\n",
    "    CLIENT_ID = credFile.readline().rstrip('\\n')\n",
    "\n",
    "    credFile.close()\n",
    "\n",
    "\n",
    "readCredsFromFile(\"..\\creds\\credFileHuman.txt\")\n",
    "\n",
    "print(\"USERNAME=\"+str(USERNAME))\n",
    "print(\"PASSWORD=\"+str(PASSWORD))\n",
    "print(\"CLIENT_ID=\"+str(CLIENT_ID))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Application Constants\n",
    "RDP_AUTH_VERSION = \"/v1\"\n",
    "RDP_FILINGS_VERSION = \"/beta1\"\n",
    "RDP_BASE_URL = \"https://api.refinitiv.com\"\n",
    "CATEGORY_URL = \"/auth/oauth2\"\n",
    "ENDPOINT_URL = \"/token\"\n",
    "CLIENT_SECRET = \"\"\n",
    "TOKEN_FILE = \"token.txt\"\n",
    "SCOPE = \"trapi\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Token Handling and Obtain a Valid Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_ENDPOINT = RDP_BASE_URL + CATEGORY_URL + RDP_AUTH_VERSION + ENDPOINT_URL\n",
    "\n",
    "\n",
    "def _requestNewToken(refreshToken):\n",
    "    if refreshToken is None:\n",
    "        tData = {\n",
    "            \"username\": USERNAME,\n",
    "            \"password\": PASSWORD,\n",
    "            \"grant_type\": \"password\",\n",
    "            \"scope\": SCOPE,\n",
    "            \"takeExclusiveSignOnControl\": \"true\"\n",
    "        }\n",
    "    else:\n",
    "        tData = {\n",
    "            \"refresh_token\": refreshToken,\n",
    "            \"grant_type\": \"refresh_token\",\n",
    "        }\n",
    "\n",
    "    # Make a REST call to get latest access token\n",
    "    response = requests.post(\n",
    "        TOKEN_ENDPOINT,\n",
    "        headers={\n",
    "            \"Accept\": \"application/json\"\n",
    "        },\n",
    "        data=tData,\n",
    "        auth=(\n",
    "            CLIENT_ID,\n",
    "            CLIENT_SECRET\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Failed to get access token {0} - {1}\".format(response.status_code, response.text))\n",
    "\n",
    "    # Return the new token\n",
    "    return json.loads(response.text)\n",
    "\n",
    "\n",
    "def saveToken(tknObject):\n",
    "    tf = open(TOKEN_FILE, \"w+\")\n",
    "    print(\"Saving the new token\")\n",
    "    # Append the expiry time to token\n",
    "    tknObject[\"expiry_tm\"] = time.time() + int(tknObject[\"expires_in\"]) - 10\n",
    "    # Store it in the file\n",
    "    json.dump(tknObject, tf, indent=4)\n",
    "\n",
    "\n",
    "def getToken():\n",
    "    try:\n",
    "        print(\"Reading the token from: \" + TOKEN_FILE)\n",
    "        # Read the token from a file\n",
    "        tf = open(TOKEN_FILE, \"r+\")\n",
    "        tknObject = json.load(tf)\n",
    "\n",
    "        # Is access token valid\n",
    "        if tknObject[\"expiry_tm\"] > time.time():\n",
    "            # return access token\n",
    "            print(tknObject[\"expiry_tm\"])\n",
    "            print(\"time.time()=\" + str(time.time()))\n",
    "            return tknObject[\"access_token\"]\n",
    "\n",
    "        print(\"Token expired, refreshing a new one...\")\n",
    "        tf.close()\n",
    "        # Get a new token from refresh token\n",
    "        tknObject = _requestNewToken(tknObject[\"refresh_token\"])\n",
    "\n",
    "    except Exception as exp:\n",
    "        print(\"Caught exception: \" + str(exp))\n",
    "        print(\"Getting a new token using Password Grant...\")\n",
    "        tknObject = _requestNewToken(None)\n",
    "\n",
    "    # Persist this token for future queries\n",
    "    saveToken(tknObject)\n",
    "#    print(\"Token is: \" + tknObject[\"access_token\"])\n",
    "    # Return access token\n",
    "    return tknObject[\"access_token\"]\n",
    "\n",
    "\n",
    "accessToken = getToken()\n",
    "print(\"Have token now\")\n",
    "print(\"Token is: \" + accessToken)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Filings Helper Function requestSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILINGS_ENDPOINT = RDP_BASE_URL+'/data-store'+RDP_FILINGS_VERSION + '/graphql'\n",
    "\n",
    "\n",
    "def requestSearch(token, payloadSearch):\n",
    "\n",
    "    global FILINGS_ENDPOINT\n",
    "    print(\"requestSearch...\")\n",
    "\n",
    "    querystring = {}\n",
    "    payload = \"\"\n",
    "    jsonfull = \"\"\n",
    "    jsonpartial = \"\"\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': \"application/json\",\n",
    "        'Authorization': \"Bearer \" + token,\n",
    "        'cache-control': \"no-cache\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(FILINGS_ENDPOINT, json={\n",
    "                             'query': payloadSearch}, headers=headers)\n",
    "\n",
    "    print(\"Response status code =\"+str(response.status_code))\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        if response.status_code == 401:   # error when token expired\n",
    "            accessToken = getToken()     # token refresh on token expired\n",
    "            headers[\"Authorization\"] = \"Bearer \" + accessToken\n",
    "            response = requests.post(FILINGS_ENDPOINT, json={\n",
    "                'query': payloadSearch}, headers=headers)\n",
    "\n",
    "    print('Raw response=')\n",
    "    print(response)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        jsonFullResp = json.loads(response.text)\n",
    "        return jsonFullResp\n",
    "    else:\n",
    "        return ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Filings by File Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following example searched for all 10-Qs on February 12, 2021\n",
    "payloadIn = \"\"\"\n",
    "{\n",
    "  FinancialFiling(filter: {AND: [\n",
    "    {FilingDocument: {DocumentSummary: {FormType: {EQ: \"10-Q\"}}}}, \n",
    "    {FilingDocument: {DocumentSummary: {FilingDate: {BETWN: {FROM: \"2021-02-12T00:00:00Z\", TO: \"2021-02-12T23:59:59Z\"}}}}}]}, \n",
    "    sort: {FilingDocument: {DocumentSummary: {FilingDate: DESC}}},\n",
    "    limit: 25 ) {\n",
    "    _metadata {\n",
    "      totalCount\n",
    "      cursor\n",
    "    }\n",
    "    FilingOrganization {\n",
    "      Names {\n",
    "        Name {\n",
    "          OrganizationName (filter: {OrganizationNameTypeCode: {EQ: \"LNG\"}}){\n",
    "            OrganizationName\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    FilingDocument {\n",
    "      Identifiers {\n",
    "        OrganizationId\n",
    "        Dcn\n",
    "      }\n",
    "      DocId\n",
    "      FinancialFilingId\n",
    "      DocumentSummary {\n",
    "        DocumentTitle\n",
    "        FeedName\n",
    "        FormType\n",
    "        HighLevelCategory\n",
    "        MidLevelCategory\n",
    "        FilingDate\n",
    "        SecAccessionNumber\n",
    "        SizeInBytes\n",
    "      }\n",
    "      FilesMetaData {\n",
    "        FileName\n",
    "        MimeType\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "jsonFullResp = requestSearch(accessToken, payloadIn)\n",
    "print('Parsed json response=')\n",
    "print(json.dumps(jsonFullResp, indent=2))\n",
    "docId = jsonFullResp[\"data\"][\"FinancialFiling\"][0][\"FilingDocument\"][\"DocId\"]\n",
    "print('DocId is', str(docId))\n",
    "cursor = jsonFullResp[\"data\"][\"FinancialFiling\"][0][\"_metadata\"][\"cursor\"]\n",
    "print('cursor is', str(cursor))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search by OrganizationId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for all filings documents for Tesla in 2021\n",
    "\n",
    "payloadIn = \"\"\"\n",
    "{\n",
    "  FinancialFiling(filter: {AND: [{FilingDocument: {Identifiers: {OrganizationId: {EQ: \"4297089638\"}}}}, \n",
    "    {FilingDocument: {DocumentSummary: {FilingDate: {BETWN: {FROM: \"2021-01-01T00:00:00Z\", TO: \"2021-12-31T11:59:59Z\"}}}}}]}, \n",
    "    sort: {FilingDocument: {DocumentSummary: {FilingDate: DESC}}}, \n",
    "    limit: 10) {\n",
    "    _metadata {\n",
    "      totalCount\n",
    "    }\n",
    "    FilingOrganization {\n",
    "      Names {\n",
    "        Name {\n",
    "          OrganizationName (filter: {OrganizationNameTypeCode: {EQ: \"LNG\"}}){\n",
    "            OrganizationName\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "    FilingDocument {\n",
    "      Identifiers {\n",
    "        OrganizationId\n",
    "        Dcn\n",
    "      }\n",
    "      DocId\n",
    "      FinancialFilingId\n",
    "      DocumentSummary {\n",
    "        DocumentTitle\n",
    "        FeedName\n",
    "        FormType\n",
    "        HighLevelCategory\n",
    "        MidLevelCategory\n",
    "        FilingDate\n",
    "        SecAccessionNumber\n",
    "        SizeInBytes\n",
    "      }\n",
    "      FilesMetaData {\n",
    "        FileName\n",
    "        MimeType\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\"\n",
    "jsonFullResp = requestSearch(accessToken, payloadIn)\n",
    "print('Parsed json response=')\n",
    "print(json.dumps(jsonFullResp, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Filings Documents\n",
    "There are four identifers or retrieval methods you can use to download a document.\n",
    "\n",
    "* FilingId (FilingId, or Financial Filing Id, is an internal permanent identifier assigned to each filings document. This is our strategic filings identifier.)\n",
    "* Dcn (Dcn, also known as Document Control Number, is an external identifier and an enclosed film-number specific to Edgar documents.)\n",
    "* DocId (DocId, or Document Identifier, is an internal identifier assigned to financial filings documents.)\n",
    "* Filename (Filename provides a faster and direct route to download documents without going through a resolver.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Helper Function retrieveURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveURL(token, retrievalParameters):\n",
    "\n",
    "    ENDPOINT_DOC_RETRIEVAL = RDP_BASE_URL+'/data/filings' + \\\n",
    "        RDP_FILINGS_VERSION + '/retrieval/search/' + retrievalParameters\n",
    "\n",
    "    headers = {\n",
    "        \"Authorization\": \"Bearer \" + token,\n",
    "        \"X-API-Key\": \"155d9dbf-f0ac-46d9-8b77-f7f6dcd238f8\",\n",
    "        \"ClientID\": \"api_playground\"\n",
    "    }\n",
    "    print(\"Next we retrieve: \" + ENDPOINT_DOC_RETRIEVAL)\n",
    "\n",
    "    response = requests.get(ENDPOINT_DOC_RETRIEVAL, headers=headers)\n",
    "\n",
    "    print(\"Response status code =\"+str(response.status_code))\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        if response.status_code == 401:   # error when token expired\n",
    "            token = getToken()     # token refresh on token expired\n",
    "            print(\"Token now is: \"+token)\n",
    "            headers[\"Authorization\"] = \"Bearer \" + token\n",
    "            response = requests.get(\n",
    "                ENDPOINT_DOC_RETRIEVAL, headers=headers)\n",
    "\n",
    "    print(\"Response status code =\"+str(response.status_code))\n",
    "    if response.status_code == 200:\n",
    "        jsonFullResp = json.loads(response.text)\n",
    "        return jsonFullResp\n",
    "    else:\n",
    "        return ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve URL by DocID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFullResp = retrieveURL(accessToken, 'docId/54932207')\n",
    "print('full response is =')\n",
    "print(json.dumps(jsonFullResp, indent=2))\n",
    "fileName = list(jsonFullResp.keys())[0]\n",
    "print(\"fileName is: \")\n",
    "print(fileName)\n",
    "signedUrl = jsonFullResp[list(jsonFullResp.keys())[0]][\"signedUrl\"]\n",
    "print(\"signedUrl to retrieve is: \")\n",
    "print(signedUrl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve URL by FilingID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonFullResp = retrieveURL(accessToken, 'filingId/97661417885')\n",
    "print('full response is =')\n",
    "print(json.dumps(jsonFullResp, indent=2))\n",
    "fileName = list(jsonFullResp.keys())[0]\n",
    "print(\"fileName is: \")\n",
    "print(fileName)\n",
    "signedUrl = jsonFullResp[list(jsonFullResp.keys())[0]][\"signedUrl\"]\n",
    "print(\"signedUrl to retrieve is: \")\n",
    "print(signedUrl)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveSaveDoc(fileName, signedUrl, token):\n",
    "\n",
    "    headers = {\n",
    "        'clientId': CLIENT_ID,\n",
    "        'Authorization': \"Bearer \" + token\n",
    "    }\n",
    "\n",
    "    response = requests.get(signedUrl, headers=headers, allow_redirects=True)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        filenameWithDir = './downloads/' + str(fileName)\n",
    "        os.makedirs(os.path.dirname(filenameWithDir), exist_ok=True)\n",
    "        open(filenameWithDir, 'wb').write(response.content)\n",
    "        print(\"The document \", fileName,\n",
    "              \" has been downloaded indo downloads subfolder\")\n",
    "        return fileName\n",
    "    else:\n",
    "        print(\"Response code on error is:\", str(response.status_code))\n",
    "        return ''\n",
    "\n",
    "\n",
    "retrieveSaveDoc(fileName, signedUrl, accessToken)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP package used to aid in text manipulation\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "# Machine Learning modules used to prepare and measure text\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, pipeline\n",
    "import torch\n",
    "# HTML text processing\n",
    "from bs4 import BeautifulSoup\n",
    "# Helper modules\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import trange  # Progress bar\n",
    "# Refinitiv packages to extract filings data and retrieve price data\n",
    "import refinitiv.data as rd\n",
    "from refinitiv.data.content import filings\n",
    "# Convenient modules to simplify API access to Filings\n",
    "%run ./FilingsQuery.ipynb\n",
    "%run ./SymbolLookup.ipynb\n",
    "pd.set_option('display.max_colwidth', 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a session to retrieve Filings data from RDP\n",
    "rd.open_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the models\n",
    "finbert = BertForSequenceClassification.from_pretrained('yiyanghkust/finbert-fls',num_labels=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the Pre-trained transformer used to process our raw text\n",
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-fls')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = nlp(\n",
    "    \"The future for next years sales will increase by 10 %.\", top_k=3)\n",
    "prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment - Download the Pre-trained transformer used to process our raw text\n",
    "sent_tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment - Download the FinBert model used to process our transformed data\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
